version: '3.8'

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    # Performance optimizations
    environment:
      # Enable GPU if available (comment out if CPU-only)
      # - NVIDIA_VISIBLE_DEVICES=all
      # - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      
      # CPU optimizations
      - OLLAMA_NUM_PARALLEL=3  # Allow 2 concurrent requests
      - OLLAMA_MAX_LOADED_MODELS=1  # Keep up to 2 models in memory
      - OLLAMA_FLASH_ATTENTION=1  # Enable flash attention for faster processing
      
    # Resource limits to prevent OOM
    deploy:
      resources:
        limits:
          memory: 8G  # Adjust based on your system
        reservations:
          memory: 4G
    
    # Shared memory for better performance
    shm_size: 2gb
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # Increased for model loading
    
    # Uncomment for GPU support
    # runtime: nvidia

  # Service to automatically pull required models with optimization
  ollama-init:
    image: curlimages/curl:latest
    container_name: ollama-init
    depends_on:
      - ollama
    volumes:
      - ./init-ollama.sh:/init-ollama.sh
    entrypoint: ["/bin/sh", "/init-ollama.sh"]
    environment:
      - OLLAMA_HOST=http://ollama:11434
    restart: "no"

  flask-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flask-benchmark-app
    ports:
      - "5000:5000"
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
      # Flask optimizations
      - FLASK_ENV=production
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  ollama_data:
    driver: local

networks:
  default:
    name: benchmark-network
    driver: bridge